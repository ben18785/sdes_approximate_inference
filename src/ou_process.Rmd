---
title: "OU process inference"
output: html_notebook
---

```{r}
library(tidyverse)
library(rstan)
library(loo)
library(RColorBrewer)
options(mc.cores=4)
rstan_options(auto_write=TRUE)
source("helper.R")
set.seed(1)
```

In this notebook, we perform inference for the Orstein-Uhlenbeck (OU) process, which is described by the following SDE:

\begin{equation}
  dX(t) = -\theta X(t) dt + \kappa dW(t).
\end{equation}

Throughout, we assume that $X(0)=10$ which is known, and $\theta$ and $\kappa$ are unknowns which we attempt to estimate. The observations are corrupted by Gaussian measurement noise of the form:

\begin{equation}
  Y(t) \stackrel{i.i.d.}{\sim} \text{normal}(X(t), \sigma).
\end{equation}

We assume that $\sigma$ is also unknown.

We first simulate some data from the OU process with measurement noise using known parameters. Exact simulation of the OU process is possible, since the following probability distribution governs the density:

\begin{equation}
X(t+\delta t) | X(t) \sim \text{normal}(X(t)\exp(-\theta \delta_t), \frac{\kappa^2}{2\theta}(1 - \exp(-2\theta \delta_t)))
\end{equation}

We first use this to simulate the state $X(t)$.
```{r}
simulate_ou <- function(X_0, T, N, theta, kappa) {
  delta_t <- T / N
  D <- kappa^2 / 2
  var <- D / theta * (1 - exp(-2 * delta_t))
  X <- vector(length = (N + 1))
  X[1] <- X_0
  for(i in 1:N) {
    X[i + 1] <- rnorm(1, X[i] * exp(-theta * delta_t), sqrt(var))
  }
  X
}

T <- 10
N <- 500
X_0 <- 10
theta <- 1
kappa <- 1
t <- seq(0, T, T/N)
X <- simulate_ou(X_0, T, N, theta, kappa)

# plot
df <- tibble(t, X)
df %>% 
  ggplot(aes(x=t, y=X)) +
  geom_line()
```
We then add measurement noise and save the data for future use.
```{r}
sigma_n <- 1
Y <- rnorm(length(X), X, sigma_n)
df <- df %>% 
  mutate(Y=Y)
df %>%
  ggplot(aes(x=t, y=Y)) +
  geom_line()
# saveRDS(df, "../data/processed/ou_simulation.rds")

# remove zero time entry as causes issues for ODE integrator in Stan
df <- df %>% 
  filter(t > 0)
```

# Exact inference
We now perform exact inference for the process. To do so, we use the result that if $X\sim \mathcal{N}(\mu, \Sigma)$ then $Y\sim \mathcal{N}(X, \sigma^2 I)$, then:

\begin{equation}
  Y\sim \mathcal{N}(\mu, \Sigma + \sigma^2 I)
\end{equation}

It is straightforward to construct the matrix $\Sigma$. To do so, we consider:

\begin{align}
  \text{cov}(X(t), X(t+\delta t)) &= \text{cov}(X(t), X(t)\exp(-\theta\delta t) + \epsilon_t)\\
  &= \text{cov}(X(t), X(t)\exp(-\theta\delta t))\\
  &= \exp(-\theta\delta t)\text{var}(X(t))
  &= \exp(-\theta\delta t) \times \kappa^2 / 2 (1 - \exp(-2\theta t))\\
  &= \kappa^2 / 2 (\exp(-\theta\delta t) - \exp(-\theta (2t + \delta_t)))
\end{align}

where $\text{var}(X(t)) = \kappa^2 / 2 (1 - \exp(-2\theta t))$ is the variance of the OU process. More generally, the covariance between $X(t_1)$ and $X(t_2)$ is given by the result:

\begin{equation}
  \text{cov}(X(t_1), X(t_2)) = \kappa^2 / 2 (\exp(\theta|t_1-t_2|) - \exp(\theta(t_1 + t_2))).
\end{equation}

```{r}
# remove first element of t and X to avoid delta
model <- stan_model("stan/ou_exact.stan")
stan_data <- list(
  nobs=nrow(df),
  t=df$t,
  Y=df$Y,
  X_0=X_0)

fit <- sampling(model, data=stan_data,
                iter=2000, chains=4)
print(fit, c("theta", "kappa", "sigma_n"))
saveRDS(fit, "../data/processed/ou_exact_fit.rds")
```

# Approximate inference using KL expansion of SDE into an ODE
Fit models with lots of different Z counts
```{r}
model_approx <- stan_model("stan/ou_approx.stan")

# fit model with many different Zs
init_fn_list <- list(
  theta=theta,
  sigma=sigma,
  sigma_n=1)
Nzs <- c(2, 4, 8, 16, 32, 64, 128)
stan_data <- list(
    nobs=nrow(df),
    t=df$t,
    Y=df$Y,
    X_0=X_0,
    T=T,
    kappa_mean=0,
    kappa_width=10)
lfits <- vector(mode="list", length = length(Nzs))
for(i in seq_along(Nzs)) {
  print(paste0("i = ", i))
  lfits[[i]] <- fit_model_any_z(
    Nzs[i], model_approx, init_fn_list, stan_data, iters=2000)
}
```

Looking at estimates of parameters as a function of N
```{r}
extract_param <- function(param_name, fit) {
  rstan::extract(fit, param_name)[[1]]
}
Ns <- c("true", Nzs)
params <- c("theta", "kappa", "sigma_n")
k <- 1
lfits <- c(fit, lfits)
for(j in seq_along(params)) {
  for(i in seq_along(lfits)) {
    draws <- extract_param(params[j], lfits[[i]])
    temp <- tibble(value=draws,
                   iter=seq_along(draws),
                   N=Ns[i],
                   param=params[j])
    if(k == 1)
      big_df <- temp
    else
      big_df <- big_df %>% bind_rows(temp)
    k <- k + 1
  }
}
big_df <- big_df %>% 
  mutate(param=as.factor(param)) %>% 
  mutate(param=fct_relevel(param, params))
saveRDS(big_df, "../data/processed/ou_approx_fits.rds")
params <- c("theta", "kappa", "sigma")
Ns <- c(rev(Ns[-1]), "actual")
big_df <- readRDS("../data/processed/ou_approx_fits.rds") %>% 
  mutate(param=as.character(param)) %>% 
  mutate(param=if_else(param=="sigma_n", "sigma", param)) %>% 
  mutate(param=fct_relevel(param, params)) %>% 
  mutate(N=if_else(N=="true", "actual", N)) %>% 
  mutate(N=fct_relevel(N, Ns)) %>% 
  mutate(type=if_else(N=="actual", "actual", "approx")) %>% 
  mutate(type=fct_relevel(type, "approx", "actual"))

cols <- brewer.pal(length(Ns) - 1, "Spectral")
cols <- c(cols, "#000000")

g <- ggplot(big_df,
       aes(x=value, colour=N)) +
  stat_density(geom="line", position="identity",
               aes(linetype=N)) +
  scale_color_manual("", values = cols) +
  scale_linetype_manual("", values=c(rep(1, length(Ns) - 1), 2)) +
  facet_wrap(~param, scales="free") +
  guides(colour = guide_legend(reverse=T),
         linetype = guide_legend(reverse=T))
ggsave("../figures/ou_fits_vs_actual.pdf", g,
       width = 8, height = 4)
```

Check convergence
```{r}
rhats <- vector(length=length(lfits))
esss <- vector(length=length(lfits))
for(i in seq_along(lfits)) {
  sum_df <- posterior::summarise_draws(lfits[[i]])
  rhats[i] <- sum(sum_df$rhat > 1.01, na.rm = T)
  bulk_ess <- sum(sum_df$ess_bulk < 400, na.rm = T)
  tail_ess <- sum(sum_df$ess_tail < 400, na.rm = T)
  esss[i] <- bulk_ess + tail_ess
}
conv_df <- tibble(
  rhat=rhats, ess=esss
)
saveRDS(conv_df, "../data/processed/ou_convergence_diags.rds")
```


Extract log-likelihoods to perform model comparison
```{r}
lfits <- lfits[-1]
loos <- vector(length = length(lfits), mode="list")
for(i in seq_along(loos)) {
  log_like <- extract_log_lik(lfits[[i]], "loglikelihood")
  loos[[i]] <- loo(log_like)
}
saveRDS(loos, "../data/processed/ou_loos.rds")
loo_compare(loos)
```

# Optimisation for AIC comparison
```{r}
Nzs <- c(2, 4, 8, 16, 32, 64, 128)
lopts <- vector(mode="list", length = length(Nzs))
for(i in seq_along(Nzs)) {
  print(paste0("i = ", i))
  lopts[[i]] <- optimise_model_any_z(
    Nzs[i], model_approx, init_fn_list, stan_data)
}

# plot AIC
lvals <- vector(length = length(Nzs))
for(i in seq_along(lvals))
  lvals[i] <- 2 * Nzs[i] - 2 * lopts[[i]]$value
g <- tibble(N=Nzs, AIC=lvals) %>% 
  ggplot(aes(x=N, y=AIC)) +
  geom_point() +
  geom_line()
ggsave("../figures/ou_aics.pdf", g,
       width = 8, height = 4)
```

# Thin series and repeat AIC exercise
```{r}
thin_series <- function(Nthin, df, T) {
  tfull <- df$t
  t <- seq(0, T, T / Nthin)
  t <- t[-1]
  Y <- approx(tfull, df$Y, t)$y
  tibble(t=t, Y=Y)
}

aic_scan <- function(df, Nzs) {
  lopts <- vector(mode="list", length = length(Nzs))
  stan_data <- list(
    nobs=nrow(df),
    t=df$t,
    Y=df$Y,
    X_0=X_0,
    T=T,
    kappa_mean=0,
    kappa_width=10)
  
  for(i in seq_along(Nzs)) {
    print(paste0("i = ", i))
    lopts[[i]] <- optimise_model_any_z(
      Nzs[i], model_approx, init_fn_list, stan_data)
  }
  lvals <- vector(length = length(Nzs))
for(i in seq_along(lvals))
  lvals[i] <- 2 * Nzs[i] - 2 * lopts[[i]]$value
  lvals
}

Nzs <- c(2, 4, 8, 16, 32, 64)
Nthins <- c(round(10^seq(1.0, 2.5, 0.5)), N)
m_aics <- matrix(nrow = length(Nzs),
                 ncol = length(Nthins))
for(i in seq_along(Nthins)) {
  print(paste0("thin = ", i))
  df_temp <- thin_series(Nthins[i], df, T)
  m_aics[, i] <- aic_scan(df_temp, Nzs)
}

m_aics <- as.data.frame(m_aics)
colnames(m_aics) <- Nthins
m_aics <- m_aics %>% 
  mutate(N=Nzs)
saveRDS(m_aics, "../data/processed/ou_aics.rds")
g <- m_aics %>% 
  pivot_longer(-N) %>% 
  mutate(name=as.factor(name)) %>% 
  mutate(name=fct_relevel(name, as.character(Nthins))) %>% 
  ggplot(aes(x=N, y=value)) +
  geom_line() +
  geom_point() +
  scale_x_log10() +
  facet_wrap(~name, scales="free")
ggsave("../figures/ou_aics_thinning.pdf", g,
       width = 12, height = 6)
```

# Test robustness of results to particular dataset
```{r}
N <- 5000
X_0 <- 10
theta <- 1
kappa <- 1
sigma_n <- 1
t <- seq(0, T, T/N)
X <- simulate_ou(X_0, T, N, theta, kappa)
df <- tibble(t, X)
Y <- rnorm(length(X), X, sigma_n)
df <- df %>% 
  mutate(Y=Y)
Nzs <- c(2, 4, 8, 16, 32, 64, 128)
Nthins <- c(round(10^seq(2, 3.5, 0.5)), N)
m_aics <- matrix(nrow = length(Nzs),
                 ncol = length(Nthins))
for(i in seq_along(Nthins)) {
  print(paste0("thin = ", i))
  df_temp <- thin_series(Nthins[i], df, T)
  m_aics[, i] <- aic_scan(df_temp, Nzs)
}

m_aics <- as.data.frame(m_aics)
colnames(m_aics) <- Nthins
m_aics <- m_aics %>% 
  mutate(N=Nzs)
saveRDS(m_aics, "../data/processed/ou_aics_bigger_sample.rds")
g <- m_aics %>% 
  pivot_longer(-N) %>% 
  mutate(name=as.factor(name)) %>% 
  mutate(name=fct_relevel(name, as.character(Nthins))) %>% 
  ggplot(aes(x=N, y=value)) +
  geom_line() +
  geom_point() +
  scale_x_log10() +
  facet_wrap(~name, scales="free")
g
ggsave("../figures/ou_aics_thinning_bigger_sample.pdf", g,
       width = 12, height = 6)
```

